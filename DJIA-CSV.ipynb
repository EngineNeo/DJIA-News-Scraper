{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts available headlines for DJIA 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMZN: 330\n",
      "AXP: 1852\n",
      "AMGN: 150\n",
      "AAPL: 469\n",
      "BA: 10\n",
      "CAT: 2299\n",
      "CSCO: 1003\n",
      "CVX: 0\n",
      "GS: 0\n",
      "HD: 2617\n",
      "HON: 0\n",
      "IBM: 1083\n",
      "INTC: 10\n",
      "JNJ: 2927\n",
      "KO: 2785\n",
      "JPM: 10\n",
      "MCD: 2208\n",
      "MMM: 1486\n",
      "MRK: 3334\n",
      "MSFT: 0\n",
      "NKE: 0\n",
      "PG: 1303\n",
      "TRV: 654\n",
      "UNH: 230\n",
      "CRM: 1476\n",
      "VZ: 2937\n",
      "V: 10\n",
      "WMT: 10\n",
      "DIS: 10\n",
      "DOW: 1224\n",
      "Total amount of headlines for all DJIA stocks: 30427\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./2009_2020_stocknews/analyst_ratings_processed.csv')\n",
    "\n",
    "with open('DJIA-30', 'r') as file:\n",
    "    stocks = file.read().split()\n",
    "\n",
    "stock_headline_count = {stock: df[df['stock'] == stock].shape[0] for stock in stocks}\n",
    "total_count = 0\n",
    "\n",
    "for stock, count in stock_headline_count.items():\n",
    "    print(f'{stock}: {count}')\n",
    "    total_count += count\n",
    "\n",
    "print(f'Total amount of headlines for all DJIA stocks: {total_count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processes the given CSV(s) to append the DJIA 30 stocks to the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_list = [\n",
    "    './2009_2020_stocknews/raw_partner_headlines.csv',\n",
    "    './2009_2020_stocknews/analyst_ratings_processed.csv'\n",
    "]\n",
    "column_mapping = {\n",
    "    'raw_partner_headlines.csv': ['date', 'stock', 'headline'],\n",
    "    'analyst_ratings_processed.csv': ['date', 'stock', 'title']\n",
    "}\n",
    "\n",
    "with open('DJIA-30', 'r') as file:\n",
    "    stocks = file.read().split()\n",
    "\n",
    "for file_path in file_list:\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    df = df[df['stock'].isin(stocks)].sort_values(by=['stock', 'date'])\n",
    "    df['date'] = df['date'].str.split(' ').str[0]\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "    columns_to_save = column_mapping[file_name]\n",
    "\n",
    "    file_exists = os.path.isfile('cleaned_stock_data_copy.csv')\n",
    "    df.to_csv('cleaned_stock_data_copy.csv', columns=columns_to_save, mode='a', index=False, header=not file_exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the original CSV to ensure no duplicates of the same date, stock, and headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed and file saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'cleaned_stock_data_copy.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "\n",
    "    duplicates = df[df.duplicated(['Date', 'Stock', 'Headline'], keep=False)].sort_values(by=['Stock', 'Headline'])\n",
    "\n",
    "    total_duplicates = len(duplicates)\n",
    "\n",
    "    if total_duplicates > 0:\n",
    "        df = df.drop_duplicates(subset=['Date', 'Stock', 'Headline'], keep='first')\n",
    "\n",
    "        df = df.sort_values(by=['Stock', 'Date'])\n",
    "\n",
    "        df.to_csv('cleaned_stock_data_copy.csv', index=False)\n",
    "        print('Duplicates removed and file saved and sorted')\n",
    "    else:\n",
    "        print(\"No duplicate headlines found within the same stock.\")\n",
    "\n",
    "except pd.errors.ParserError as e:\n",
    "    print(f\"ParserError: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
